# -*- coding: utf-8 -*-
"""Recession Prediction ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vop1RDAuh3-2VjbY0erCXNbCmEKIHQS3

# Machine Learning for Recession Prediction
### Garrett Laverty, Sam Asebrook, Ethan Chapel
Survive and Conquer

---

### Imports
"""

# Imports
# Add any necessary imports here
# Basics have been added

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from scipy import stats
import statsmodels.api as smf
from sklearn import metrics
from sklearn.model_selection import train_test_split

"""### Creating the Dataframe"""

# Create dataframe
# Add Sam's file to the file path and create a dataframe here

data_recession = pd.read_csv('/content/CSE432_RecessionData - Sheet1.csv') #use this if file is in csv format
#data = pd.read_excel('insert excel name here') #use this instead if file is in excel format

df_recession = pd.DataFrame(data = data_recession)
df_recession['Recession'] = df_recession['Recession'].astype('float64')
df_recession = df_recession.drop(columns=['Date'])

#df_recession = df_recession.drop(df_recession.index[:458])

df_recession = df_recession.drop(columns=['Credit_Card_Interest_Rate'])

df_recession = df_recession.drop(columns=['Automobile_Sales_Ratio'])

df_recession = df_recession.drop(columns=['NASDAQ100_Index_Change'])
'''
df_recession = df_recession.drop(columns=['3_Month_Treasury_Bill_Market_Rate'])
df_recession = df_recession.drop(columns=['10_Year_Treasury Bond_Maturity'])
'''
#df_recession.info()
df_recession.tail(30)
#df_recession["Recession"].value_counts()

"""### Data Preprocessing"""

# Data preprocessing
# Configure data here

df_recession = df_recession.dropna()
#df_recession.fillna(0, inplace=True)
print(df_recession.shape)

"""### Correlation Matrix
*Determine which values are most closely related*
"""

plt.figure(figsize=(10, 8))  # Adjust the width and height as needed
sns.heatmap(df_recession.corr(), annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.show()

"""### Splitting the Data"""

# Data splitting
# Split the data based on values chosen from correlation matrix

features = df_recession.drop(columns=['Recession'])
X_train, X_test, y_train, y_test = train_test_split(features, df_recession["Recession"], test_size=0.3, random_state=40)

#X_train = (X_train - X_train.min()) / (X_train.max() - X_train.min())

#X_test = (X_test - X_test.min()) / (X_test.max() - X_test.min())

"""### Training And Eval"""

from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import RidgeClassifier
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.svm import SVC
import scipy.stats as si
import statsmodels.api as sm
from sklearn.metrics import accuracy_score
from sklearn.ensemble import BaggingClassifier
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import confusion_matrix
from imblearn.metrics import specificity_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error

#======================================================================== Linear Regression
lm = LinearRegression()
lm.fit(X_train,y_train)
predictions = lm.predict(X_test)
y_predictions = []
for y_pred in predictions:
  if y_pred > 0.4:
    y_predictions.append(1.)
  else:
    y_predictions.append(0.)

#parameters = {'normalize': [True, False]}

# Perform grid search
#grid_search = GridSearchCV(lm, parameters, cv=5, scoring='accuracy')
#grid_search.fit(X_train, y_train)

# Get the best model
#best_lm = grid_search.best_estimator_

#print(best_lm)

print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== SVM model
svm_model = SVC(kernel = 'poly', degree=9, random_state=12)
svm_model.fit(X_train, y_train)
# Predict the class for the test dataset
y_predictions = svm_model.predict(X_test)
print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== KNN
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)

y_predictions = knn.predict(X_test)

print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== AdaBoosting

# Create and train the AdaBoost classifier
adaboost = AdaBoostClassifier(n_estimators=30, random_state=42)
adaboost.fit(X_train, y_train)


#Predict the response for test dataset
y_predictions = adaboost.predict(X_test)
print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== Decision Tree

clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_predictions = clf.predict(X_test)
print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== Bagging After Decision Tree

bagging = BaggingClassifier(estimator=clf, n_estimators=35, random_state=42)
bagging.fit(X_train, y_train)

#Predict the response for test dataset
y_predictions = bagging.predict(X_test)
print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== Random Forest
random_forest = RandomForestClassifier(n_estimators=15, random_state=42)
random_forest.fit(X_train, y_train)

#Predict the response for test dataset
y_predictions = random_forest.predict(X_test)

print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== Ridge Classification
ridge_classifier = RidgeClassifier(alpha=1, class_weight='balanced', solver='auto')
ridge_classifier.fit(X_train, y_train)
y_predictions = ridge_classifier.predict(X_test)

print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== Lasso Logit
# Create and train the Lasso logistic regression model
lasso_logit = LogisticRegression(penalty='l2', solver='liblinear', C=1.5)
lasso_logit.fit(X_train, y_train)
y_predictions = lasso_logit.predict(X_test)

print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== Regularized Discriminant Analysis
rda_classifier = QuadraticDiscriminantAnalysis(reg_param=0.5)  # Set regularization parameter
rda_classifier.fit(X_train, y_train)
y_predictions = rda_classifier.predict(X_test)

print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#=================================================================================== Linear instead b/c smple sizes of classes are not equal (i.e. RDA bad)
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import confusion_matrix

# Create an instance of the LDA model
lda = LinearDiscriminantAnalysis()

# Fit the model to your training data
lda.fit(X_train, y_train)

# Make predictions on the test data
y_predictions = lda.predict(X_test)

print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== Probit

# Fit the Probit regression model
probit_model = sm.Probit(y_train, X_train)
probit_result = probit_model.fit()
# Predict class probabilities
y_prob = probit_result.predict(X_test)
# Convert probabilities to binary predictions
y_predictions = np.where(y_prob >= 0.4, 1, 0)
print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== Gaussian Boosting

from sklearn.naive_bayes import GaussianNB
gaussian = GaussianNB()
gaussian.fit(X_train, y_train)
y_predictions = gaussian.predict(X_test)
print("Accuracy =", accuracy_score(y_test, y_predictions))
print("Precision =", precision_score(y_test, y_predictions))
print("Recall =", recall_score(y_test, y_predictions))
print("Specificity =", specificity_score(y_test, y_predictions))
print("F1 =", f1_score(y_test, y_predictions))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, y_predictions)

#======================================================================== RandomSearch model for finding best weights

from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.model_selection import RandomizedSearchCV
import numpy as np
from sklearn.model_selection import cross_val_score

# Define a custom estimator
class WeightedEnsemble(BaseEstimator, ClassifierMixin):
    def __init__(self, weights, threshold=1.0):
        self.weights = weights
        self.threshold = threshold

    def fit(self, X, y):
        pass

    def predict(self, X):
        all_predictions = np.zeros((X.shape[0], len(self.weights)))
        all_models = [lm, svm_model, knn, adaboost, random_forest, bagging, ridge_classifier, lasso_logit, lda, probit_result, gaussian]
        for i, model in enumerate(all_models):
            all_predictions[:, i] = model.predict(X)
        return (np.dot(all_predictions, self.weights) > self.threshold).astype(int)


# Define the hyperparameter space for weights
param_dist = {
    'weights': [np.random.uniform(-0.1, 1.5, size=11) for _ in range(800)],  # Generating 600 random sets of weights
    'threshold': [np.random.uniform(1.1, 2.0) for _ in range(800)]# Generating 600 random thresholds for classifying as recession or not
}

# Initialize RandomizedSearchCV
random_search = RandomizedSearchCV(estimator=WeightedEnsemble(weights=[1] * 11), param_distributions=param_dist, n_iter=800, cv=6, scoring=['recall', 'accuracy'], refit='recall', random_state=42)

# Perform randomized search
random_search.fit(X_train, y_train)

# Get the best weights
best_weights = random_search.best_params_['weights']
best_threshold = random_search.best_params_['threshold']
best_accuracy = random_search.best_score_

print("Best weights:", best_weights)
print("Best threshold:", best_threshold)
print("Best accuracy:", best_accuracy)

#======================================================================== Final model predictions with weights from randomSearch

import warnings
from sklearn.exceptions import UndefinedMetricWarning
from sklearn.model_selection import GridSearchCV

warnings.filterwarnings("ignore", category=UserWarning)

# Predictions from each individual model
allPredictions = [0] * 11

# All the final predictions from the overall model, to be evaluated against y_test
finalPreds = []

 # Dummy values, create an actual formula to generate weights
weights = best_weights # [7.69188935, 8.42871409, 1.71385758, 2.74054559, 3.81764405, 6.82834151, 7.53600156, 5.80337071, 7.90889566, 1.29473677]
for i in X_test.index:
  curPred = 0
  sample = X_test.loc[i]
  sample = sample.values.reshape(1, -1)
  allPredictions[0] = lm.predict(sample)
  allPredictions[1] = svm_model.predict(sample)
  allPredictions[2] = knn.predict(sample)
  allPredictions[3] = adaboost.predict(sample)
  allPredictions[4] = random_forest.predict(sample)
  allPredictions[5] = bagging.predict(sample)
  allPredictions[6] = ridge_classifier.predict(sample)
  allPredictions[7] = lasso_logit.predict(sample)
  allPredictions[8] = lda.predict(sample)
  allPredictions[9] = probit_result.predict(sample)
  allPredictions[10] = gaussian.predict(sample)
  for i in range(11):
    curPred += allPredictions[i] * weights[i]
  if curPred > best_threshold:
    finalPreds.append(1.)
  else:
    finalPreds.append(0.)

print("Accuracy =", accuracy_score(y_test, finalPreds))
print("Precision =", precision_score(y_test, finalPreds))
print("Recall =", recall_score(y_test, finalPreds))
print("Specificity =", specificity_score(y_test, finalPreds))
print("F1 =", f1_score(y_test, finalPreds))
mse = mean_squared_error(y_test, y_predictions)
print("Mean Squared Error:", mse)
confusion_matrix(y_test, finalPreds)